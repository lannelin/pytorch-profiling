seed_everything: true

trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: null

  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      entity: __replace__
      project: profiling
      name: __replace__
      log_model: false

  callbacks:
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: step

  log_every_n_steps: 10
  fast_dev_run: false
  max_epochs: 10
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  check_val_every_n_epoch: 1
  num_sanity_val_steps: null
  enable_checkpointing: null
  enable_progress_bar: null
  enable_model_summary: null
  accumulate_grad_batches: 1
  gradient_clip_val: null
  gradient_clip_algorithm: null
  deterministic: null
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: null

model:
  class_path: pytorch_profiling.example.vit.ViTB16
  init_args:
    num_classes: 102
    freeze_embedding: true

    optimizer:
      class_path: torch.optim.SGD
      init_args:
        lr: 0.01
        momentum: 0.9
        weight_decay: 0.0

    scheduler:
      class_path: torch.optim.lr_scheduler.CosineAnnealingLR
      init_args:
        T_max: 319 # |train| * epochs / batch size = 1020*10/32=319

    scheduler_config:
      interval: step



data:
  class_path: pytorch_profiling.example.data.Flowers102DataModule
  init_args:
    data_dir: ./data
    num_workers: 0
    batch_size: 32
    train_transform: &train_transform
      class_path: torchvision.transforms.Compose
      init_args:
        transforms:
          - class_path: torchvision.transforms.Resize
            init_args:
              size: [224, 224]
          - class_path: torchvision.transforms.ToTensor
          - class_path: torchvision.transforms.Normalize # imagenet mean and std
            init_args:
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]


    val_transform: *train_transform
    test_transform: *train_transform

    download: true
